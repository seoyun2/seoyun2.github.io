---
title: "[CS231N] 5. Convolutional Neural Networks"
categories:
  - cs231n
  - Image Classification
tags:
  - cs231
  - image classification
toc: true
toc_sticky: true
toc_label: "On This Page"
toc_icon: "bookmark"
use_math: true
---


💡 Iamge Classification <br>
Stanford University "CS231N" 강의를 듣고 정리하였습니다. <br>
{: .notice--info}


자막 : https://github.com/visionNoob/CS231N_17_KOR_SUB (크롬 확장 프로그램 Subtitles for Youtube) <br>
2017 버전 강의 목차 및 슬라이드 : http://cs231n.stanford.edu/2017/syllabus.html <br>
2017 버전 강의 동영상 링크 : https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv <br>
2022 버전 강의 목차 및 슬라이드 : http://cs231n.stanford.edu/schedule.html <br>
실습 과제 : https://github.com/cs231n/cs231n.github.io/tree/master/assignments <br>
{: .notice}

# Lecture 5 : Convolutional Neural Networks 

**Fully Connected Layer**

<img width="1099" alt="L5_01" src="https://user-images.githubusercontent.com/86525868/172630031-51a8c7f6-8c22-4828-b993-c731bdc1d0a1.png">{: width="50%" height="50%"}{: .align-center}

32x32x3 Image가 input값으로 들어오면 3072x1의 행렬로 길게 펴서 가중치(10x3072)와 곱하는 과정으로 activation(출력, 1x10)값을 얻음<br>



**Convolution Layer**

![L5_02](https://user-images.githubusercontent.com/86525868/172630052-27873bd3-b83a-478d-ac85-555a9f64b47e.jpg)

Fully Connected Layer와 다르게 기존의 구조를 보존시켜 filter라는 가중치로 슬라이딩 하면서 내적을 수행하고 activation map이라는 결과를  얻음 (filter는 원하는 만큼 사용할 수 있음)

![L5_03](https://user-images.githubusercontent.com/86525868/172630057-cee942c2-3c5f-4f9e-b369-a39e32f57fa7.gif){: width="50%" height="50%"}{: .align-center}



슬라이딩을 한 칸씩 하는 모습을 볼 수 있는데 슬라이딩하며 움직이는 칸을 Stride라고 함

$$
(N-F)/\text{stride}+1
$$

공식을 통해 ($N$=input image의 열(행), $F$=filter의 열(행)) 출력사이즈를 계산 할 수 있음



## Padding 

input 주변에 공간을 더하는 것을 의미

1. 여러개의 filter를 지나다 보면 이미지의 크기가 작아지고 데이터가 부족한 상황이 생길 수 있음

  <img width="1096" alt="L5_04" src="https://user-images.githubusercontent.com/86525868/172630069-5a27fab9-be19-4fb3-835c-5877f073b220.png">{: width="50%" height="50%"}{: .align-center}

2. 모서리 pixel은 중앙부 pixel 보다 적게 사용됨 → 모서리에 중요한 정보가 담겨 있는 이미지라면 손실이 발생



### Zero-Padding 

<img width="376" alt="L5_05" src="https://user-images.githubusercontent.com/86525868/172630071-1b12f50d-b1bf-4a5e-8f71-5749800cbf04.png">{: width="20%" height="20%"}{: .align-center}

이미지 주변에 0이라는 pixel을 둘러 input image pixel을 많이 활용할 수 있게 함

이 경우 stride가 1이라면 output의 크기는 $(N+2-F)/1+1=7$으로 7x7을 출력 → **입출력 크기를 동일하게 만들어줌**



### Example

Input volume: $32\times32\times3$, 10 $5\times5$ filter with stride 1, pad2

1. Output volume size : $(32+2\times2-5)/1+1=32$, so $32\times32\times\times10$

2. Number of parameters in this layer : each filter has $(5\times5\times3+1)\times10=760$

   $5\times5$ filter의 depth가 $3$ + bias값인 $1$ $\times$10개의 filter
   
   
[Intuitively Understanding Convolutions for Deep Learning](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)

## Pooling Layer

Down sampling 할 때 사용 → layer들을 지나가면서 학습이 이루어지는 중간에 신경망의 계산 효율성과 메모리 요구량 감소등의 이유로 사용 

<img width="546" alt="L5_06" src="https://user-images.githubusercontent.com/86525868/172888220-ef05a0a4-19c8-41be-be8b-9eaa1caf672b.png">{: width="50%" height="50%"}{: .align-center}

### MAX Pooling

<img width="969" alt="L5_07" src="https://user-images.githubusercontent.com/86525868/172888238-af4f2553-ae4b-4538-8b7f-f7b4bf5fb83b.png">{: width="30%" height="30%"}{: .align-center}

depth에는 영향을 주지 않고 data를 공간적으로 줄여줌 (MAX Pooling이 일반적으로 쓰임)

<img width="698" alt="L5_08" src="https://user-images.githubusercontent.com/86525868/172888242-c5aaa9ee-f88a-448c-bab8-24aa3334b78b.png">{: width="50%" height="50%"}{: .align-center}
