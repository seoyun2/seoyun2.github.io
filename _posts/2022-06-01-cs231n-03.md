---
title: "[CS231N] 4. Intruduction to Neural Networks"
categories:
  - cs231n
  - ImageClassification
tags:
  - cs231
  - image classification
toc: true
toc_sticky: true
toc_label: "On This Page"
toc_icon: "bookmark"
use_math: true
---


ğŸ’¡ Iamge Classification <br>
Stanford University "CS231N" ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤. <br>
{: .notice--info}


ìë§‰ : https://github.com/visionNoob/CS231N_17_KOR_SUB (í¬ë¡¬ í™•ì¥ í”„ë¡œê·¸ë¨ Subtitles for Youtube) <br>
2017 ë²„ì „ ê°•ì˜ ëª©ì°¨ ë° ìŠ¬ë¼ì´ë“œ : http://cs231n.stanford.edu/2017/syllabus.html <br>
2017 ë²„ì „ ê°•ì˜ ë™ì˜ìƒ ë§í¬ : https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv <br>
2022 ë²„ì „ ê°•ì˜ ëª©ì°¨ ë° ìŠ¬ë¼ì´ë“œ : http://cs231n.stanford.edu/schedule.html <br>
ì‹¤ìŠµ ê³¼ì œ : https://github.com/cs231n/cs231n.github.io/tree/master/assignments <br>
{: .notice}

# Lecture 4 : Intruduction to Neural Networks

## Analytic gradient (using Computational graphs)

![L4_01](https://user-images.githubusercontent.com/86525868/171412748-514cbc3a-3ae5-4004-86ae-242278eead2b.png){: .align-center}

**inputì´ $x, W$ì¸ Linear Classifier**

* íŒŒë¼ë¯¸í„° Wì™€ ë°ì´í„° xì˜ ê³±ì…ˆì€ score vectorë¥¼ ì¶œë ¥í•¨ 

* hinge lossë¼ëŠ” ë‹¤ë¥¸ ê³„ì‚° ë…¸ë“œë¥¼ ê°€ì§€ê³  ìˆê³  ë°ì´í„° í•­$ L_i$ë¥¼ ê³„ì‚°í•˜ëŠ”ë°, ì˜¤ë¥¸ìª½ í•˜ë‹¨ì— ë³´ì´ëŠ” Regularization ë˜í•œ ê°€ì§€ê³  ìˆìŒ

* ì´ ë…¸ë“œ(R)ëŠ” regularizationí•­ì„ ê³„ì‚°í•˜ê³  ìµœì¢… loss, Lì€ regularization í•­ê³¼ ë°ì´í„° í•­ì˜ í•©ì„

* computational graphë¥¼ ì‚¬ìš©í•´ì„œ í•¨ìˆ˜ë¥¼ í‘œí˜„í•˜ê²Œ ë¨ìœ¼ë¡œì¨ back propagationì„ ì‚¬ìš©í• ìˆ˜ ìˆê²Œ ë¨

  * back propagationì€ gradientë¥¼ ì–»ê¸° ìœ„í•´ computataional graph ë‚´ë¶€ì˜ ëª¨ë“  ë³€ìˆ˜ì— ëŒ€í•´ chain ruleì„ ì¬ê·€ì ìœ¼ë¡œ ì‚¬ìš© 

    

![L4_02](https://user-images.githubusercontent.com/86525868/171412761-d62d56e9-df79-42c1-a374-8d2fdc32dd6a.png){: width="50%" height="50%"}{: .align-center}

ìˆ˜ì—…ì—ì„œ ì‚¬ìš©í•  CNNì˜ ê°€ì¥ ìœ„ì¸µì— ì…ë ¥ ì´ë¯¸ì§€ê°€ ë“¤ì–´ê°€ê³  ì•„ë˜ì—ëŠ” lossê°€ ìˆìŒ â†’ ì…ë ¥ ì´ë¯¸ì§€ëŠ” loss functionìœ¼ë¡œ ê°€ê¸°ê¹Œì§€ ë§ì€ layerë¥¼ ê±°ì³ ë³€í˜•ì„ ê²ªê²Œ ë¨



## Backpropagation : a simple example

$$
f(x, y, z)=(x+y)z
$$

ìš°ì„  ëª©í‘œëŠ” í•¨ìˆ˜ë¥¼ ê°€ì§€ëŠ” ê²ƒ (ì´ ê²½ìš°ì˜ í•¨ìˆ˜ëŠ” fë¡œ ì •ì˜í•¨) â†’ ê·¸ë¦¬ê³  function $f$ì˜ ì¶œë ¥ì— ëŒ€í•œ ì–´ë–¤ ë³€ìˆ˜ì˜ gradientë¥¼ ì°¾ê¸° ì›í•¨

1. í•­ìƒ í•¨ìˆ˜ $f$ë¥¼ ì´ìš©í•´ì„œ computational graphë¡œ ë‚˜íƒ€ëƒ„ 

    í•¨ìˆ˜ë¥¼ graphë¡œ ë‚˜íƒ€ë‚´ê³  ì´ ë„¤íŠ¸ì›Œí¬ì— ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” ê°’$(x=-2, y=5, z=-4)$ë¥¼ ì „ë‹¬ <br>

    ![L4_03](https://user-images.githubusercontent.com/86525868/171412767-fc5767cd-4d76-42bd-bb7c-f68652ddce89.png){: width="60%" height="60%"}{: .align-center}

    $x+y$ ë§ì…ˆ ë…¸ë“œì˜ ì´ë¦„ì€ $q$ì´ê³ , $x$ì™€ $y$ì— ê°ê°ì— ëŒ€í•œ $q$ì˜ gradientëŠ” ë‹¨ìˆœ ë§ì…ˆì´ê¸° ë•Œë¬¸ì— ê°’ì€ 1

    $q$ì™€ $z$ì— ëŒ€í•œ $f$ ì˜ gradientëŠ” ê³±ì…ˆ ê·œì¹™ì— ì˜í•´ ê°ê° $z$ì™€ $q$ â†’ __ì°¾ê³ ì í•˜ëŠ”ê²ƒì€ $x, y, z$ ê°ê°ì— ëŒ€í•œ $f$ì˜ gradient__ <br>
    
    

2. backpropagationì€ chain ruleì˜ ì¬ê·€ì ì¸ ì‘ìš© (chain ruleì— ì˜í•´ ë’¤ì—ì„œë¶€í„° ì‹œì‘)

   ![L4_04](https://user-images.githubusercontent.com/86525868/172428544-c3953338-615d-43c5-98f5-6ddb2438c9aa.png){: width="40%" height="40%"}{: .align-center}

   ì¶œë ¥ $f$ì— ëŒ€í•œ gradientë¥¼ ê³„ì‚°í•˜ë©´ 1

   ê·¸ ë‹¤ìŒì—” ë’¤ë¡œ ì´ë™í•´ì„œ $z$ì— ëŒ€í•œ $f$ì˜ gradientë¥¼ ê³„ì‚°í•˜ë©´ $z$ì— ëŒ€í•œ $f$ ë¯¸ë¶„ì´ $q$

   ![L4_05](https://user-images.githubusercontent.com/86525868/172428557-c5e529d0-785e-4b09-8929-9e52d6625043.png){: width="40%" height="40%"}{: .align-center}

   $q$ì— ëŒ€í•œ $f$ì˜ gradientëŠ” $z$ â†’  $z$ëŠ” -4ì˜ ê°’ì„ ê°€ì§

   ![L4_06](https://user-images.githubusercontent.com/86525868/172428560-813c5473-9d18-473c-aea6-032848cca7ed.png){: width="40%" height="40%"}{: .align-center}


   $y$ì— ëŒ€í•œ $f$ì˜ ë¯¸ë¶„ê°’ì„ ì•Œê³  ì‹¶ì§€ë§Œ $y$ëŠ” $f$ì™€ ë°”ë¡œ ì—°ê²°ë˜ì–´ ìˆì§€ ì•ŠìŒ â†’  $f$ëŠ” $z$ì™€ ì—°ê²°ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— chain ruleì„ ì´ìš©

   ![L4_07](https://user-images.githubusercontent.com/86525868/172428568-ca19b8ee-3f11-4be5-86f5-b125f26ef4e2.png){: width="40%" height="40%"}{: .align-center}

   $x$ì— ëŒ€í•œ $f$ì˜ ë¯¸ë¶„ê°’ë„ ë™ì¼ 

   ![L4_08](https://user-images.githubusercontent.com/86525868/172428574-5637313b-a870-4406-8306-7e81e9da0755.png){: width="40%" height="40%"}{: .align-center}

   ![L4_10](https://user-images.githubusercontent.com/86525868/172428579-79ba4500-9150-4301-b658-f800e2f84978.png){: width="40%" height="40%"}{: .align-center}



Chain ruleì„ í™œìš©í•´ì„œ ë³µì¡í•œ ì¸µì˜ ë¯¸ë¶„ê°’ì„ local gradient $\times$ upstream gradient ì˜ ê³¼ì •ìœ¼ë¡œ gradientë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ



### Another Example 

![L4_11](https://user-images.githubusercontent.com/86525868/171990884-f892bd94-5f17-4f15-8836-4d088d5cc885.JPG){: .align-center}

![L4_12](https://user-images.githubusercontent.com/86525868/171990887-9ae42d20-2c8c-4701-82da-f86af12b4662.JPG){: .align-center}

![L4_13](https://user-images.githubusercontent.com/86525868/171990890-ce287e95-53fd-43aa-9673-22d0373b2d1e.JPG){: .align-center}

![L4_14](https://user-images.githubusercontent.com/86525868/171990891-f4117fa4-ac7a-4574-8bcd-1917027c6f75.JPG){: .align-center}

![L4_15](https://user-images.githubusercontent.com/86525868/171990892-e9d43d86-c879-42d3-955b-31ade44bfebb.JPG){: .align-center}

![L4_16](https://user-images.githubusercontent.com/86525868/171990894-c046e5d1-7841-4cd7-9e79-c08d098502ce.JPG){: .align-center}

![L4_17](https://user-images.githubusercontent.com/86525868/171990895-775fbeb9-9501-4a0a-b475-dad9cb93b8df.JPG){: .align-center}

![L4_18](https://user-images.githubusercontent.com/86525868/171990896-e610b43d-345c-43a3-915c-a70e36398cf6.JPG){: .align-center}

**ì •ë¦¬**

![L4_bonus](https://user-images.githubusercontent.com/86525868/171990898-aeb0046c-4ebc-42a7-a0d6-c0823c2c2805.png){: .align-center}

### í™œìš© : Sigmoid Function

![L4_19](https://user-images.githubusercontent.com/86525868/172049931-8acba6f7-2956-4e04-831f-c3547ec35039.png){: .align-center}

ìœ„ì˜ ì‹ì˜ $w_0x_0+w_1x_1+w_2$ë¥¼ $x$ë¡œ ì¹˜í™˜í•˜ë©´ sigmoid function â†’ sigmoid functionì˜ ë¯¸ë¶„ê°’ì€ $(1-\sigma(x))(\sigma(x))$ ì´ê¸° ë•Œë¬¸ì— ë³µì¡í•œ ê³„ì‚° ê³¼ì • ì—†ì´ í•œë²ˆì— $0.20$ ë¼ëŠ” gradientë¥¼ êµ¬í•  ìˆ˜ ìˆìŒ

**ë˜í•œ, êµ­ì†Œì ì¸ ê³„ì‚°($w_0x_0+w_1x_1+w_2$ì„ ë³´ë‹¤ ê°„ë‹¨í•œ $x$ë¡œ ë¬¶ìŒ)ì´ ê°€ëŠ¥** <br>

**Patterns in backward flow**

<img width="634" alt="L4_20" src="https://user-images.githubusercontent.com/86525868/172427715-c860fe2c-2505-482c-9fc7-5dae83cfcea0.png">{: width="50%" height="50%"}{: .align-center}

1. **ADD gate** : gradient distributor â†’ upstream gradientì˜ ê°’ì„ local gradientì— ë‚˜ëˆ ì¤Œ 
2. **MAX gate** : gradient router â†’ ì…ë ¥ê°’ì´ í° local gradientì— upstream gradientì˜ ê°’ì„ ì£¼ê³  ì…ë ¥ê°’ì´ ì‘ì€ ìª½ì— 0ì„ ì¤Œ 
3. **MUL gate** : gradient switcher â†’ local gradient $\times$ ë‹¤ë¥¸ ë³€ìˆ˜ì˜ ê°’ <br>

## Gradients for Vectorized Code

ì´ì œ input ê°’ì´ ìŠ¤ì¹¼ë¼ê°€ ì•„ë‹Œ ë²¡í„°ì˜ í˜•íƒœì¼ ë•Œ

![L4_10](https://user-images.githubusercontent.com/86525868/172428579-79ba4500-9150-4301-b658-f800e2f84978.png){: width="60%" height="60%"}{: .align-center}

ì…ë ¥ê°’ $x, y$ê°€ ë²¡í„°ì˜ í˜•íƒœë¼ë©´ local gradientëŠ” **Jacobian matrix**ì˜ í˜•íƒœë¥¼ ê°€ì§€ê²Œ ë¨ 

<img width="635" alt="L4_21" src="https://user-images.githubusercontent.com/86525868/172428717-53ed4919-cda5-4d06-8bd4-433404c33bfd.png">{: width="60%" height="60%"}{: .align-center}

ì—¬ê¸°ì„œ í•„ìš”í•œ ë¶€ë¶„ì€ Jacobian matrixì˜ ëŒ€ê°í–‰ë ¬ <br>



### A Vectorized Example 

$$
f(x, W)=||W \cdot x||^2=\sum_{i=1}^2(W \cdot x)_i^2
$$

![L4_22](https://user-images.githubusercontent.com/86525868/172428734-620f0a2c-1af7-4195-84f3-f4e3ee88d465.JPG){: width="60%" height="60%"}{: .align-center}

![L4_23](https://user-images.githubusercontent.com/86525868/172428745-97e2389c-cc59-40ad-ae59-73fda2d45ef4.JPG){: width="60%" height="60%"}{: .align-center}

![L4_24](https://user-images.githubusercontent.com/86525868/172428671-73d24735-7f5f-4100-b44b-3731b40b0f24.JPG){: width="60%" height="60%"}{: .align-center}

![L4_25](https://user-images.githubusercontent.com/86525868/172428686-c1b2c655-b357-455c-a4b7-1d3f0379ba8a.JPG){: width="60%" height="60%"}{: .align-center}

**Point!**

1. gradientëŠ” í•­ìƒ ë³€ìˆ˜ì™€ ê°™ì€ shape
2. gradientëŠ” ê° ìš”ì†Œê°€ ìµœì¢… ì¶œë ¥ì— ì˜í–¥ì„ ì–¼ë§Œí¼ ë¯¸ì¹˜ëŠ”ì§€ ì •ëŸ‰í™”í•¨
3. forward pass ê°’ì„ ì €ì¥í•´ì•¼ backward passì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
