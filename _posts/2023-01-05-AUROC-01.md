---
title: "[Data Analysis] 3. Confusion Matrix"
categories:
  - Data Analysis
  - Confusion Matrix
tags:
  - Data Analysis
  - Confusion Matrix
toc: true
toc_sticky: true
toc_label: "On This Page"
toc_icon: "bookmark"
use_math: true
---


# 분류 모형 성능 평가 

**학습 데이터에 대해서 100% 정확한 모형을 만들면 좋은 것인가?**

![1](https://user-images.githubusercontent.com/86525868/210344273-1813269b-941d-401f-817a-8c4a1385455b.png)

Training data에 대해서 빨간색 경계면은 완벽하게 분류하고 있지만 파란색 경계면은 다소 오분류된 것을 볼 수 있음 → 빨간 경계면이 파란 경계면 보다 좋은가?

**NO!** 

![2](https://user-images.githubusercontent.com/86525868/210344285-13b62708-2f39-4232-a978-110acc92f1bb.png)

모델이 학습 데이터에 존재하는 **노이즈(컨트롤 불가능한 변동성)**까지 외우게 되어 새로운 데이터에 적용할 경우 예측 성능이 저하되는 과적합(Overfitting) 발생 → Training data, Validation data, Test data에 존재하는 노이즈가 다르기 때문 !



**data를 나눠서 사용하는 이유**

: 분류, 회귀문제를 풀 수 있는 다양한 알고리즘이 존재하고 어떤 알고리즘은 최적의 하이퍼파라미터 설정이 필요함 → **validation set 사용**

: 주어진 문제를 해결하기 위한 최적의 방법론을 선택하기 위해 개별 모델을 **동등한 조건**에서 평가할 필요가 있음 → **test set 사용**

* **검증 데이터** : 다양한 파라미터 조합 중 최적의 파라미터를 찾는 데 주로 사용
* **테스트 데이터** : 여러 기계학습 알고리즘 중 최적의 알고리즘을 찾는데 주로 사용 
