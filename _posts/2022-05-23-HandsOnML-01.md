---
title: "[Hands On ML] 한눈에 보는 머신러닝"
categories:
  - Hands On ML
tags:
  - machineLearning
  - statistics
toc: true
toc_sticky: true
toc_label: "On This Page"
toc_icon: "bookmark"
use_math: true
---


💡 Hands On Machine Learning <br>
오렐리앙 "핸즈온 머신러닝"을 보고 정리하였습니다.
{: .notice--info}

## 한눈에 보는 머신러닝

### 머신러닝 시스템의 종류

#### 지도학습과 비지도 학습

* 지도학습(supervised learning) : 정답이 훈련데이터에 포함되어 있음

  * 대표적인 예 :
  
    - 분류(classification) - 스팸 필터

    - 회귀(regression) - 중고차 가격 예측 (특성을 나타내는 예측변수를 사용해 가격이라는 타겟수치 예측)

    

* 비지도 학습(unsupervised learning) : 정답이 훈련데이터에 포함되어 있지 않음

  * 대표적인 예 : 
  
    - 군집(clustering) - 블로그 방문자들이 어떤 그룹에 속하는지 

    -	차원축소(dimensionality reduction) - 정보를 최대한 살리면서 데이터 간소화 ( = 특성추출, feature extraction)

    - 시각화(visualization) - 정답이 없는 대규모의 고차원 데이터를 도식화 가능한 2D, 3D로 만들어줌

    - 이상치 탐지(outlier detection) - 학습알고리즘에 주입하기 저, 데이터셋에서 이상한 값을 자동으로 제거 

    - 연관 규칙 학습(association rule learning) - 대량의 데이터에서 특성간 흥미로운 관계 찾음



* 준지도 학습(semisupervised learning) : 일부만 레이어가 있는 데이터를 훈련데이터로 사용 or 지도 학습 + 준지도 학습

  * 대표적인 예 : 호스팅 서비스 

    ​	     심층 신뢰 신경망(deep belidf network) - RBM이 순차적으로 비지도 학습 훈련한 뒤 전체가 지도 학습으로 조정됨

    

* 강화 학습(reinforcement learning) : 에이전트(학습하는 시스템), 환경을 관찰해서 행동하고 그 결과로 보상 또는 벌점을 받음 

  ​				시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습
  
  
#### 배치 학습과 온라인 학습

* 배치학습(batch learning) : 시스템이 점진적으로 학습할 수 없으며 가용한 데이터를 모두 사용해 훈련하기 때문에 오프라인에서 수행

  ​			새로운 종류의 스팸 데이터에 대해 학습하려면 전체 데이터(기존 + 새로운)로 훈련한뒤 교체해야 함

  ​			**단점** : 많은 컴퓨팅 자원과 많은 비용이 발생

  

* 온라인 학습(online learning) : 데이터를 순차적으로 미니배치 단위로 주입하여 시스템을 훈련시킴

  ​			    매 학습 단계가 빠르고 비용이 적게 들어 데이터가 도착하는 대로 즉시 학습 가능 

  ​			    중요한 파라미터는 변하는 데이터에 얼마나 빠르게 적응하는지를 나타낸 학습률(learning rate)

  ​			    __단점__ : 나쁜 데이터가 들어왔을 때 성능이 점진적으로 감소함 


#### 사례 기반 학습과 모델 기반 학습 (어떻게 일반화 되는가)

* 사례 기반 학습 : 



​		스팸 메일과 매우 유사한 메일을 구분하도록 프로그래밍 하고 두 메일 사이의 유사도를 측정

​		스팸 메일과 공통으로 가지고 있는 단어가 많으면 스팸으로 분류 

---

### 시계열 분석 절차

1. 시계열 데이터 생성
    - 시계열 객체 (time series object) 생성
    - 시계열 객체에는 관측값뿐만 아니라 시계열의 시작 시점과 종료 시점, 주기(월별, 분기별, 연도별) 등의 정보 포함
2. 탐색적 분석을 통해 데이터의 특성 이해
    - 시각화(visualization) 작업을 통해 시계열 데이터의 변동 패턴 관찰
    - 성분 분해(component decomposition) 작업을 통해 추세, 계절, 불규칙 성분으로 세분화
3. 미래 관측값에 대한 예측
    - 지수 모델링(exponential modeling) 기법 → 관측값의 가중통계를 바탕으로 예측 수행
    - ARIMA(autoregressive integrated moving average) 기법 → 관측값과 오차의 상관을 바탕으로 예측 수행
    

## 시계열 데이터 분해

### 시계열 데이터 분해 개요

시계열 데이터 분해(time series decomposition)는 시계열 데이터의 관측값을 변동 요인에 따라 구성 성분으로 분해하는 과정이다. 

시계열 데이터는 일반적으로 관측값의 전반적 상승 또는 하락 경향을 나타내는 추세 성분과 설명 안되는 오차(error)를 나타내는 불규칙 성분으로 구성된다. 

시계열 데이터에 주기가 존재하고 계절적 요인의 영향을 받아 변동한다면 계절 성분이 추가로 포함된다. 

### 비계절 데이터 분해

불규칙적 변동 요인을 제거 또는 완화하여 의미있는 추세 패턴 파악

1. 평활법(smoothing method) 
  * 단순이동 평균(simple moving average) / 중심이동평균(centered moving average)

    $$y'_t=(y_{t-m}+\cdots+y_t+\cdots+y_{t+m})/k$$
    
    ![1-1](https://user-images.githubusercontent.com/86525868/138905555-26086199-6970-4f6b-a139-51940c6f92bf.png)
    {: .align-center}
    
    여기서 $y'_t$은 $t$ 시점에서의 이동평균에 의해 평활된 값, $y_t$는 $t$ 시점에서의 관측값이다. 
    
    $k$ 는 평균을 산출하기 위해 사용되는 관측값의 개수 ($k=2m+1$), 시계열 데이터의 양쪽 끝의 $\frac{k-1}{2}$개의 관측값은 계산에서 제외된다.
    
### 계절 데이터 분해

- 추세 성분 : 시간 흐름에 따른 수준(level, 즉 관측값의 크기)의 변화
- 계절 성분 : 단위 기간 내에서의 순환 주기의 영향
- 불규칙 성분 : 추세 성분과 계절 성분에 의해 설명되지 않는 영향

1. 가법 모델 (additive model)
    
    $y_t=T_t+S_t+I_t$
    
      $y_t$는 $t$ 시점에서의 관측값, 
    
      $T_t$는 $t$ 시점에서의 추세효과에 의한 기여분
    
      $S_t$는 $t$ 시점에서의 계절효과에 의한 기여분
    
      $I_t$는 $t$ 시점에서의 불규칙효과에 의한 기여분 
    
    ![1-2](https://user-images.githubusercontent.com/86525868/138907006-0b948d74-aedd-4e11-ab1c-0da7ba09b4a9.JPG)
    
    상승하는 추세가 존재, 계절에 따른 주기적 등락, 각 관측값에서의 불규칙한 변동 포함
    
2. 승법 모델 (multiplicative model)
    
    $y_t=T_t\times S_t \times I_t ~~ \Leftrightarrow ~~ log(y_t)=log(T_t\times S_t \times I_t )=log(T_t)+log(S_t)+log(I_t)$

    ![1-3](https://user-images.githubusercontent.com/86525868/138907102-7bf2012d-a66b-4ece-9d78-7f772ae13418.JPG)
    
    상승하는 추세가 존재, 계절에 따른 주기적 등락, 각 관측값에서의 불규칙한 변동 포함
    
## 지수예측 모델

### 지수예측모델 개요

- 지수예측모델(exponential forecasting model)은 단순하면서도 비교적 우수한 단기예측 성능을 보임
- 유형
    - 단순지수평활법(simple exponential smooting) : 수준 추정
    - 홀트지수평활법(Holt exponential smooting) : 수준, 기울기 추정
    - 홀터-윈터스 지수평활법(Holt-Winters exponential smooting) : 수준, 기울기, 계절 요인 추정

## ARIMA 예측모델

### 정상성

ARIMA 예측 모델은 시계열 데이터의 정상성(stationarity)를 가정한다. 

정상성(stationarity)는 정상(normal)이 아닌 시계열 데이터의 특성이 시간의 흐름에 따라 변하지 않는다는 것을 의미한다. 

정상(stationarity) 시계열은 장기적으로 예측 가능한 패턴을 갖지 않으며, 시계열 그래프는 일정한 변동폭(=일정한 분산)을 가지면서 대체로 수평에 가까운 패턴(=일정한 평균)을 보인다. 

데이터가 정상성을 가진다는 것은 평균과 분산이 안정화되어 있어서 분석하기 쉽다는 것을 의미한다.

![1-5](https://user-images.githubusercontent.com/86525868/138909007-6b0c039a-b8e0-4a10-ac48-4d31a3da4f57.JPG)

(a) 시간에 흐름에 따라 증가하는 추세, 일정한 주기를 갖는 계절적 등락이 보임

(b) 뚜렷한 증가 패턴이 보임

(c) 수준의 변화가 보임

(d) 정상성 충족 

- 추세나 계절 요인은 시간이 경과하면서 관측값에 영향을 미치기 때문에 추세 성분이나 계절 성분을 갖는 시계열은 비정상적(non-stationary)
- 불규칙 성분만으로 구성된 시계열은 정상적(stationary) : 어느 시점에서 관찰하는 관측값은 불규칙한 변동을 제외하면 동일한 모습을 가짐
- 추세나 계절 요인이 포함되어 있어서 데이터가 정상성을 갖지 않으면 모델링하여 분석하는 것이 어렵기 때문에 일반적으로 정상성을 갖도록 전처리 수행

### 자기상관

정상 시계열은 어느 시계열 구간에서 관찰하든 평균과 분산이 일정하며 관측값 간의 공분산도 일정하다.

이는 자기상관(autocorrelation)이 시간에 따라 변화하지 않는다는 것을 의미한다. 

자기상관은 동일한 변수를 시점을 달리하여 관찰하였을 때, 이 관측값들 사이의 상호 관련된 정도를 나타내는 척도이다. 

자기상관은 시차(lag)를 적용한 시계열 데이터를 이용하여 계산한다. (시차를 적용한다는 것은 특정 시차만큰 관측값을 뒤로, 즉, 과거의 시점으로 이동시키는 것을 의미한다.)

![1-6](https://user-images.githubusercontent.com/86525868/138909127-9578d2b9-1a2e-4d1e-8527-8dd4131c24c9.JPG)

(시차 1 의 시계열 데이터는 관측값이 왼쪽으로 한 칸 이동, 시차 2 의 시계열 데이터는 관측값이 왼쪽으로 두 칸 이동, 시차 2 의 시계열 데이터는 관측값이 왼쪽으로 세 칸 이동한다.)

### 자기상관함수

자기상관은 다른 시점의 관측값 간 상호 연관성을 나타내므로, 시차를 적용한 시계열 데이터 간의 상관관계를 의미한다. 

자기상관 $AC_k$는 원래의 시계열 데이터($y_t$)와 $k$ 시차가 고려된, 즉, $k$ 기간 뒤로 이동한 시계열 데이터 ($y_{t-k}$) 간의 상관관계로 정의한다. 

- $AC_1$은 시차 0 시계열 데이터와 시차 1 시계열 데이터 간의 상관관계,  $AC_0$은 동일한 시계열 데이터 간의 상관관계이므로 항상 1의 값을 가진다.
- $AC_1$은 시차 0 시계열 데이터 $\{1871 : 1120, 1872 : 1160, 1873 : 963, ...\}$와 시차 1 시계열 데이터$\{1870 : 1120, 1871 : 1160, 1872 : 963, ...\}$와의 상관관계를 나타낸다.

시차에 따른 일련의 자기상관 $\{AC_1, AC_2, \cdots, AC_k\}$를 자기상관함수(autocorrelation function, $ACF$)라고 한다.

ACF는 시차에 따른 관측값 간의 연관 정도를 보여주며, 시차가 커질수록 ACF는 점차 0에 가까워진다. 

ACF는 시계열의 정상성을 평가할 때 유용하다.

- 정상 시계열의 ACF는 상대적으로 빨리 0으로 접근한다.
- 비정상 시계열의 ACF는 천천히 감소하며 종종 큰 양의 값을 가진다.

### 편자기상관함수

편자기상관(parital autocorrelation)은 시차가 다른 두 시계열 데이터 간의 순수한 상호 연관성을 나타낸다.

편자기상관 $PAC_k$는 원래의 순수한 데이터($y_t$)와 시차 $k$ 시계열 데이터 ($y_{t-k}$)간의 순수한 상관관계로서 두 시점 사이에 포함된 모든 시계열 데이터 ($y_{t-1}, y_{t-2}, \cdots, y_{t-k+1}$)의 영향은 제거된다. 

- $y_1$ 은 인접한 $y_{2}$와 직접적 연관성이 있고, $y_2$ 는 $y_3$와 연관성이 있기 때문에 인접하지 않은 $y_1, y_3$도 직접적인 상관관계를 갖는 것 처럼보일 수 있다. 편자기상관은 중간 연결고리 역할을 하는 $y_2$와의 상관관계를 배제함으로써, 관측값간의 좀 더 명확한 관련성을 파악할 수 있게 한다.

시차에 따른 일련의 편자기상관($\{PCA_1, PAC_2, \cdots, PAC_k\}$를 편자기상관함수(partial auto correlation function, $PACF$)라고 한다. 

### ACF, PACF 도표

시계열 데이터의 정상성 평가와 ARIMA 모델의 parameter 결정 및 모델의 적합도 평가에 사용된다.

![1-7](https://user-images.githubusercontent.com/86525868/138909298-894d4a1d-22a2-44b1-9e52-f4f85214578d.JPG)

  (a)의 비정상 시계열은 상승하는 추세를 볼 수 있고 이에 대응되는 ACF 도표는 자기상관이 크고 양수이며 천천히 감소하는 패턴을 보여준다

  (b)의 정상 시계열에 대응되는 ACF도표는 모든 시차에서 0에 근접한 자기상관을 보여준다. 

- ACF 도표의 파란색 선은 자기상관이 0이라는 주장에 대한 95% 신뢰구간을 나타내며, 산출된 자기상관이 통계적으로 0인지 검정한다.

### 정상 시계열로의 변환

변동폭이 일정하지 않으면 로그 변환을 통해 시간의 흐름에 따라 분산이 일정하게 유지되는 정상 시계열로 변환한다. 

추세나 계절적 요인이 관촬되면 차분(differencing, 시계열 $y_t$의 각 관측값을 $y_t-y_{t-1}$로 대체) 과정을 통해 전 기간에 걸쳐 평균이 일정한 정상 시계열로 변환한다. 

변동폭이 일정하지 않고 추세와 계절적 요인 또한 존재하면 로그 변환과 차분과정을 모두 적용하여 정상 시계열로 변환한다.

![1-8](https://user-images.githubusercontent.com/86525868/138909381-1d3fcd9a-1437-4fa7-81e0-6880a2ae0d2f.JPG)

  (a) 변동폭이 일정하지 않고 추세와 계절적 영향이 존재하는 비정상 시계열 : 패턴을 추측할 수 있지만 수의적으로 모델링하여 분석하기엔 복잡하다.

  (b) 로그 변환을 통해 좀 더 단순화된 일정한 분산을 갖는 시계열로 변환 : 단순화되었지만 시간에 흐름에 따라 수준 자체가 증가하는 경향을 설명할 수 있어야 한다.

  (c) 차분을 통해 0을 중심으로 평균이 일정하게 유지되는 패턴으로 변환 : 변동폭이 증가함에 따라 분석이 어려워진다. 

  (d) 로그 변환과 차분을 함께 적용하여 평균과 분산이 일정하게 되는 정상 시계열로 변환 : 반복되는 불규칙한 변동만 설명하면 되는 단순한 시계열이 된다.

⇒ 이처럼 시계열 데이터가 정상성을 가지면 복잡성이 줄기 때문에 효과적으로 시계열 분석을 수행할 수 있음
