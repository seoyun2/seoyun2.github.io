---
title: "[Hands On ML] 한눈에 보는 머신러닝"
categories:
  - Hands On ML
tags:
  - machineLearning
  - statistics
toc: true
toc_sticky: true
toc_label: "On This Page"
toc_icon: "bookmark"
use_math: true
---


💡 Hands On Machine Learning <br>
오렐리앙 "핸즈온 머신러닝"을 보고 정리하였습니다.
{: .notice--info}

## 한눈에 보는 머신러닝

### 머신러닝 시스템의 종류

#### 지도학습과 비지도 학습

* 지도학습(supervised learning) : 정답이 훈련데이터에 포함되어 있음

  * 분류(classification) - 스팸 필터

  * 회귀(regression) - 중고차 가격 예측 (특성을 나타내는 예측변수를 사용해 가격이라는 타겟수치 예측)

    

* 비지도 학습(unsupervised learning) : 정답이 훈련데이터에 포함되어 있지 않음
  
  * 군집(clustering) - 블로그 방문자들이 어떤 그룹에 속하는지 

  *	차원축소(dimensionality reduction) - 정보를 최대한 살리면서 데이터 간소화 ( = 특성추출, feature extraction)

  * 시각화(visualization) - 정답이 없는 대규모의 고차원 데이터를 도식화 가능한 2D, 3D로 만들어줌

  * 이상치 탐지(outlier detection) - 학습알고리즘에 주입하기 저, 데이터셋에서 이상한 값을 자동으로 제거 

  * 연관 규칙 학습(association rule learning) - 대량의 데이터에서 특성간 흥미로운 관계 찾음



* 준지도 학습(semisupervised learning) : 일부만 레이어가 있는 데이터를 훈련데이터로 사용 or 지도 학습 + 준지도 학습

  * 호스팅 서비스 

  * 심층 신뢰 신경망(deep belidf network) - RBM이 순차적으로 비지도 학습 훈련한 뒤 전체가 지도 학습으로 조정됨

    

* 강화 학습(reinforcement learning) : 에이전트(학습하는 시스템), 환경을 관찰해서 행동하고 그 결과로 보상 또는 벌점을 받고 시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습
  
  
#### 배치 학습과 온라인 학습

* 배치학습(batch learning) : 시스템이 점진적으로 학습할 수 없으며 가용한 데이터를 모두 사용해 훈련하기 때문에 오프라인에서 수행, 새로운 종류의 스팸 데이터에 대해 학습하려면 전체 데이터(기존 + 새로운)로 훈련한뒤 교체해야 함

  * **단점** : 많은 컴퓨팅 자원과 많은 비용이 발생

  

* 온라인 학습(online learning) : 데이터를 순차적으로 미니배치 단위로 주입하여 시스템을 훈련시킴, 매 학습 단계가 빠르고 비용이 적게 들어 데이터가 도착하는 대로 즉시 학습 가능, 중요한 파라미터는 변하는 데이터에 얼마나 빠르게 적응하는지를 나타낸 학습률(learning rate)

  * __단점__ : 나쁜 데이터가 들어왔을 때 성능이 점진적으로 감소함 


#### 사례 기반 학습과 모델 기반 학습 (어떻게 일반화 되는가)

* 사례 기반 학습 : 

![image-20210916203456830](https://user-images.githubusercontent.com/86525868/169726184-01b4120c-7d51-4b0e-852f-6ecbd5d70f26.png)

  스팸 메일과 매우 유사한 메일을 구분하도록 프로그래밍 하고 두 메일 사이의 유사도를 측정

  스팸 메일과 공통으로 가지고 있는 단어가 많으면 스팸으로 분류 

* 모델 기반 학습 : 

![image-20210916203629105](https://user-images.githubusercontent.com/86525868/169726780-12da10c9-0600-4002-8f8e-0e70cc6cba97.png){: .align-center}

  샘플들의 모델을 만들어 예측에 사용

![image-20210916203859413](https://user-images.githubusercontent.com/86525868/169726811-1b72db8d-16ee-4ab6-9ef4-3e9915f70f25.png){: .align-center}

  
   삶의 만족도는국가의 1인당 GDP가 증가할 수록 선형적으로 올라감 

    -> __선형함수__로 모델링 , __"삶의\_만족도 = $\theta_0+\theta_1~\times$ 1인당\_GDP"__ 

    모델은 파라미터 $\theta_0, \theta_1$을 가지고, 이 파라미터에 따라 선형함수를 표현하는 모델을 얻을 수 있음 
    
![image-20210916204509440](https://user-images.githubusercontent.com/86525868/169726830-1c81b078-fa0c-4e8e-822e-8ad144cbbf72.png)



$\theta_0, \theta_1$를 정의할 땐, 모델의 비용함수를 정의해 비용함수가 최소가 되는 값을 찾는 훈련을 시킴
    
    
* 머신러닝 프로젝트의 형태

  1. 데이터 분석
  2. 모델 선택
  3. 훈련데이터로 모델 훈련 (비용함수를 최소화하는 모델 파라미터 탐색)
  4. 새로운 데이터 적용한 뒤 예측

#### 머신러닝의 주요 도전 과제

* 충분하지 않은 양의 훈련 데이터 : 대부분의 머신러닝 알고리즘은 데이터가 많아야 잘 작동함

* 대표성 없는 훈련 데이터 :

    일반화가 잘 되려면 훈련 데이터가 일반화하기 원하는 사례를 잘 대표하는 것이 중요함 
    (샘플이 작으면 sampling noise가 발생하고 큰 샘플이더라도 표본 추출 방법이 잘못되면 sampling bias가 발생할 수 있음)

* 낮음 품질의 데이터 : 

    낮은 품질의 데이터는 내제된 패턴을 찾기 어렵기 때문에 데이터 정제가 필요함 
    (일부 샘플이 이상치라는 게 명확할 경우, 결측치가 있을 경우 빠진 값을 채울지, 제외할지)

* 관련성 없는 특성 : 

    훈련에 사용할 좋은 특성을 찾는 것을 특성 공학(feature engineering)이라고 함 
     (feature selection - 가지고 있는 특성 중 훈련에 유용한 특성 선택, feature extraction - 특성을 결합하여 유용한 특성 만듦)

* 훈련 데이터 과대적합 : 훈련 데이터에만 특화된 알고리즘(일반성이 떨어짐)

    __해결방법__ 
  
     1. 파라미터 수가 적은 모델 선택, 훈련 데이터 특성 수 줄이기, 모델 규제화 
     2. 훈련 데이터를 더 많이 모으기
     3. 훈련데이터 잡음 줄이기 

* 훈련 데이터 과소 적합 : 모델이 단순해 데이터의 내재된 구조를 학습하지 못할 때 발생

    __해결방법__ 
  
      1. 모델 파라미터가 더 많은, 강력한 모델 선택 
      2. 학습 알고리즘에 더 좋은 특성 제공(feature engineering)
      3. 모델 규제 x



#### 테스트와 검증

모델이 새로운 샘플에 일반화가 잘 되는지 아는 방법은 새로운 샘플에 실제로 적용해 보는 것 ❗ -> __훈련데이터를 training set, test set으로 나눔__

training set으로 모델을 훈련하고 test set으로 모델을 평가함으로써 오차에 대한 추정값을 얻음(새로운 샘플에 얼마나 잘 작동할지)

**하이퍼파라미터 튜닝과 모델 선택** 

  적용할 수 있는 하이퍼파라미터 100개 중 최적의 하이퍼파라미터를 찾기 위해 training set으로 훈련을 시키고 test set으로 평가하는 방법을 사용했을 때, 일반화 오차가 가장 낮은 모델을 만드는 하이퍼파라미터는 최적의 하이퍼파라미터라고 할 수 없음

  ( -> 일반화 오차를 test set에서 여러 번 측정했으므로 모델과 하이퍼파라미터가 test set에 최적화된 모델을 만들었기 때문)

  __해결방법__

  1. 홀드아웃 검증(holdout validation) : training set의 일부를 떼어 validation set을 만들어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택 

     __단점__ : validation set이 너무 작으면 정확하게 평가할 수 없음 

  2. 교차 검증(cross-validation) : validation set마다 나머지 데이터에서 훈련한 모델을 해당 validation set에서 평가함 

     __단점__ : 훈련시간이 validations et의 개수에 비례해 늘어남 



  __데이터 불일치__ : 쉽게 많은 양의 훈련 데이터를 얻을 수 있지만 이 데이터가 실제 제품에 사용될 떼이터를 완벽하게 대표하지 못할 수 있음

    __예시__ : 꽃 사진을 찍으면 꽃 이름을 자동으로 찾아주는 모바일 앱 

      웹에서 꽃 사진을 수백만개 다운로드 할 순 있지만 모바일 앱에서 실제로 유저들이 찍는 사진을 완벽하게 대신하지는 못함 

      대신할 수 있는 사진(실제 앱으로 찍은 사진)은 10,000개만 있을 수 있음 

      이런 경우 validation set과 test set가 실전에서 기대하는 데이터를 가능한 한 잘 대표해야 한다는 것이 중요함 

      -> validation set과 test set에 대표 사진이 배타적으로 포함되어야하기 때문에 반은 validation set에, 반은 test set에 넣음 

      하지만, 모델 성능이 낮을 때 training set에 과적합된 것인지, 웹사진과 모바일 앱 사진의 데이터가 불일치하기 때문인지 알기 어려움

  __해결방법__ 

   * 웹에서 다운로드한 training set의 일부를 떼어내 훈련-개발 세트(train-dev set)을 만들어, 모델을 training set으로 훈련시키고 trainig-dev set에서 평가함.

      이 모델이 validation set에서 성능이 낮다면 문제는 데이터 불일치이고 성능이 높다면 training set에 과적합된 것 
