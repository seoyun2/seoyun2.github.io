---
title: "[Data Analysis] 1. Multiple Linear Regression Analysis"
categories:
  - Data Analysis
  - Linear Regression
tags:
  - Data Analysis
  - Linear Regression
toc: true
toc_sticky: true
toc_label: "On This Page"
toc_icon: "bookmark"
use_math: true
---

# 다중 선형 회귀 모형 : Multivariate Linear Regression

**목적** : 종속변수 $Y$와 설명변수 집합 $x_1, x_2, \cdots, x_p$ 사이의 관계를 선형으로 가정하고 이를 가장 잘 설명할 수 있는 회귀 계수(Regression coefficients)를 추정 

$$
y=\beta_0+\beta_1x_1+\cdots+\beta_dx_d+\epsilon \ \ \ \ \Longrightarrow \ \ \ \ \hat{y}=\hat{\beta_0}+\hat{\beta_1}x_1+\cdots+\hat{\beta_dx}_d
$$

우리가 알고있는  $y, x_1, x_2, \cdots, x_d$ 를 통해 미지수(파라미터) $\hat{\beta_0}, \hat{\beta_1}, \cdots, \hat{\beta_d}$ 를 추정하여 $y$와 가장 유사한 값 $\hat{y}$를 찾는 모형

  **회귀 모형에서의 노이즈(noise, $\epsilon$)란?** : 데이터 생성 및 수집 과정에서 발생할 수 있는 여러 원인들에 의해 발생하는 변동성 

즉, 선형 회귀 모형은 반응변수들과 설명변수 사이의 관계를 선형으로 표현 → $\hat{y}=\hat{\beta_0}+\hat{\beta_1}x_1+\cdots+\hat{\beta_dx}_d$

<img width="623" alt="01" src="https://user-images.githubusercontent.com/86525868/191927081-5b20568d-fb3c-4da6-9bc0-9c30e34edc02.png">{: width="50%" height="50%"}{: .align-center}

그렇다면, 어떤 직선이 설명변수와 종속변수를 가장 잘 표현하는가 → **최소자승법: Ordinary Least Squares(OLS)**

## 최소자승법 : Ordinary Least Squares(OLS) 

: 추정된 회귀식에 의해 결정된 값과 실제 종속변수 값의 차이를 최소한으로 줄이는 것을 목적

<img width="679" alt="02" src="https://user-images.githubusercontent.com/86525868/191927090-1edadd1f-b83c-41e3-be7d-361bcaf8ff5f.png">

{실제값 - 예측값}을 모두 더하게 되면 부호가 달라져 측정에 어려움이 있음 → 제곱하여 더하는 것이 최소자승법

$$
\text{Actual target}:\ y=\beta_0+\beta_1x_1+\cdots+\beta_dx_d+\epsilon \\
\text{Predicted target}:\ \hat{y}=\hat{\beta_0}+\hat{\beta_1}x_1+\cdots+\hat{\beta_dx}_d\\
\\
\text{OLS}:\ \min\frac{1}{2}\sum_{i=1}^n(y_i-\hat{h_i})^2=\frac{1}{2}(y_i-(\hat{\beta_0}+\hat{\beta_1}x_{i1}+\cdots+\hat{\beta_d}x_{id}))^2
$$

**행렬을 이용한 해 구하기**

$\bold{X}:n \times (d+1) \text{ matrix}, \quad \bold{y}: n \times 1 \text{vector}$

$\hat{\beta}:(d+1)\times 1 \text{ vector}$ 

<img width="457" alt="03" src="https://user-images.githubusercontent.com/86525868/191927096-f80cd6de-4eeb-4886-822f-9de8a2b68547.png">

$$
\begin{align}
\min E(X)&=\frac{1}{2}\Big(y-X\hat{\beta} \Big)^T\Big(y-X\hat{\beta}\Big)\\
\frac{\partial E(X)}{\partial \hat{\beta}}&=-X^T\Big(y-X\hat{\beta}\Big)=0\\
&=-X^Ty+X^TX\hat{\beta}=0\\
\Rightarrow \hat{\beta}&=\Big(X^TX\Big)^{-1}X^Ty
\end{align}
$$

**선형 회귀 분석에서 최소자승법(OLS)를 이용할 경우 $\hat{\beta}$ , 학습 데이터에 대해 유일하고 명시적인 해가 존재**

  : $X, y$ 라는 이미 데이터를 통해 알고 있는 값의 조합으로 $\hat{\beta}$ 이라는 미지수를 찾기 때문에 하나의 해가 존재 (Nural Network에서는 해당하지 않음)

<img width="686" alt="04" src="https://user-images.githubusercontent.com/86525868/191927097-8a33903a-70b0-41d1-b852-0e120cdaa7af.png">

**만족해야하는 조건**

1. 오차항 $\epsilon$ 이 정규분포

  <img width="716" alt="05" src="https://user-images.githubusercontent.com/86525868/191927103-19f3d2d0-7826-4fb6-bcd7-b129a37d4aae.png">

  오잔차의 분포를 나타내는 QQ plot에서 정규분포를 벗어남, histogram에서도 확인 가능 

2. 설명변수와 종속변수 사이에 선형관계가 성립

3. 각 관측치들은 서로 독립

4. 종속변수 $y$에 대한 오차항은 설명변수 값의 범위에 관계없이 일정 (homoskedasticity)

  ![06](https://user-images.githubusercontent.com/86525868/191927106-20375aaf-5cbe-473c-b480-223834e040fa.png)
  
  (a) : 종속변수의 추정값이 증가할수록 잔차값도 증가하는 추세 

  (b) : 평균은 0으로 일정하지만 $\hat{y}$값이 커질수록 변동성이 커짐 

  (c) : 이차항 형태를 보임

  (d) : 어떠한 값의 크기에 관계없이 추세나 변동성을 보이지 않음



## 다중 선형 회귀 모형 : 회귀 모형의 적합도 


<img width="496" alt="07" src="https://user-images.githubusercontent.com/86525868/191927114-bee94a9d-0445-49d3-b391-7bea2f78f975.png">

데이터를 얼마나 잘 설명하고 있는지를 하나의 숫자로 어떻게 측정하느냐 → 회귀 모형의 적합도 

  ↳ 데이터의 종속변수($y$)가 갖는 변동성을 이용해서 계산
  
$$
\begin{align}
\sum_{i=1}^n(y_i-\bar{y})^2 &= \sum_{i=1}^n(y_i-\hat{y_i}+\hat{y_i}-\bar{y})^2\\
&=\sum_{i=1}^n(\hat{y_i}-\bar{y})^2+\sum_{i=1}^n(y_i-\hat{y})^2+2\sum_{i=1}^n(\hat{y_i}-\bar{y})(y_i-\hat{y})\\
&=\sum_{i=1}^n(y_i-\bar{y})^2+\sum_{i=1}^n\hat{\epsilon}^2
\end{align}
$$

**종속변수의 전체 변동성(분산) = 회귀식이 설명할 수 있는 변동성 + 회귀식이 설명할 수 없는 변동성**

<img width="425" alt="08" src="https://user-images.githubusercontent.com/86525868/191927116-cc22a35a-9ae3-4a81-a534-232a2fb0401f.png">

좋은 회귀모형이란 종속변수의 전체 변동성중에서 회귀식이 설명할 수 있는 변동성이 커야하고 회귀식이 설명할 수 없는 변동성(잔차)가 작아야함 → 이것을 수치화 한 것이 결정계수, $R^2$

**회귀 모형의 적합도 (결정계수, $R^2$) = 전체 변동성 중 회귀식이 설명할 수 있는 변동성의 비율**

$$
R^2=1-\frac{SSE}{SST}=\frac{SSR}{SST}\qquad \qquad 0\leq R^2\leq1
$$

<img width="371" alt="09" src="https://user-images.githubusercontent.com/86525868/191927121-0061a2e7-2574-4eb5-999c-b077a86b2ffe.png">

* $R^2=1$ → 회귀직선으로  $Y$의 총변동이 완전히 설명됨 (모든 측정값들이 회귀직선 위에 있는 경우)

* $R^2=0$  → 추정된 회귀직선은 $X$ 와 $Y$ 의 관계를 전혀 설명하지 못함

<img width="579" alt="10" src="https://user-images.githubusercontent.com/86525868/191927124-3461b4ec-26b6-41b4-8067-2721264250c9.png">

선형회귀분석을 했을 때 $R^2$가 높게 나왔을 때는 분석을 잘 한 것이 아니라 데이터의 입력변수와 출력변수 사이에 강한 선형관계가 있음으로 해석

하지만 $R^2$ 는 유의하지 않은 변수가 추가되어도 항상 증가함 → Adjusted $R^2$는 이러한 단점을 앞에 계수를 곱해줌으로써 보정 

$$
R^2_{adj}=1-\Big[\frac{n-1}{n-{(p+1)}}\Big]\frac{SSE}{SST}\leq 1-\frac{SSE}{SST}=R^2
$$

변수의 수 $p$가 커지게 되면 $R^2_{adj}$는 작아지게 됨 → **변수가 충분한 상황에서 SSE를 줄일 수 없는 효과가 없는 변수가 추가되면 $R^2{adj}$는 변수가 추가됨에 따라 작아질 수 있음**

<img width="795" alt="11" src="https://user-images.githubusercontent.com/86525868/191927128-e95b271e-b2fa-4a29-917b-4c2096970a53.png">

  Adjusted $R^2$를 사용하면 변수를 무작정 추가하는 상황을 피할 수 있음 
  
## 예시 : 도요타 코롤라 중고차 가격 예측

![12](https://user-images.githubusercontent.com/86525868/191927138-c1c6563f-b2f6-40fb-9421-269a64beaa19.png)

1. 데이터 전처리 : 변수 Fuel_Type은 카테고리형 변수이기 때문에 1-of-C coding(one-hot-encoding) 변환 

2. 데이터 구분 : 가용한 모든 데이터를 전부 학습에 사용하면 과적합 위험 (60%를 training data, 40%를 test data로 사용)



**다중회귀분석 결과 해석**

1. 유의 확률 p-value

   선형 회귀 분석에서 해당 변수가 통계적으로 유의미한지 알려주는 지표

   0에 가까울수록 모델링에 중요한 변수이며, 1에 가까울수록 유의미하지 않은 변수 

   특정 유의수준($\alpha$)을 설정하여 해당 값 미만의 변수만을 사용하여 다시 선형회귀분석을 구축하는 것도 가능 (주로 $\alpha=0.05$ 사용)

   <img width="530" alt="13" src="https://user-images.githubusercontent.com/86525868/191927144-11dcf04e-c014-4681-8216-4dc4e844f420.png">

  $H_0:\hat{\beta}_i=0$ → 귀무가설 : 설명변수가 종속변수에 영향을 끼치지 않는다 

  $H_1:\hat{\beta}_i\neq 0$ → 대립가설 : 설명변수가 종속변수에 영향을 끼친다

  귀무가설을 지지한다(=대립가설을 기각한다)는 설명변수가 종속변수에 영향을 끼지지 않는 것을 의미하고 대립가설을 지지한다(=귀무가설을 기각한다)는 설명변수가 종속변수에 영향을 끼치는 것을 의미함  

  ↳ **p-value값이 작으면 작을수록 귀무가설을 기각할 가능성이 높음** → **p-value가 작을수록 중요한 변수**

  즉, p-value를 통해 `Age_08_04(출시월), KM(주행거리), Fuel_Type_Petrol(가솔린 여부), HP(마력), Quarterly_Tax(세금), Weight(공차중량)`가 중요한 변수

   

2. 회귀 계수 Coefficient 

   $\hat{y}=\hat{\beta_0}+\hat{\beta_1}x_1+\cdots+\hat{\beta_dx}_d$에서 각 변수에 대응 하는 $\beta$값을 의미 

   해당 변수가 1단위 증가할 때 종속변수의 변화량을 의미

   양수이면 해당 설명변수와 종속변수는 양의 상관관계, 음수이면 음의 상관관계를 뜻함 

   <img width="526" alt="14" src="https://user-images.githubusercontent.com/86525868/191927146-82a17371-6a0b-408d-a0af-3712d50ca8ac.png">

   `Age_08_04`의 회귀 계수는 -123.8319168 → 나머지 모든 조건이 동일한 상황에서 1개월 이후 출시되면 가격은 약 123유로만큼 낮아진다. 

   `KM`의 회귀 계수는 -0.02 → 나머지 모든 조건이 동일한 상황에서 1km 더 주행했을 경우 가격은 0.02유로만큼 낮아진다. 

   ↳ 그렇다고해서 `Age_08_04`가 `KM`보다 회귀 계수가 더 높다고해서 더 중요한 변수는 아님 (두 변수 사이의 측정 단위가 다르기 때문)



### 회귀모형 성능 평가 

**분류문제나 회구문제를 풀 수 있는 다양한 알고리즘 존재**

- Classification : Naive bayes, Linear discriminant, K-nearest neighbor, Classification trees, etc
- Prediction : Mutiple linear regression, Neural networks, Regression trees, etc

**어떤 알고리즘은 최적의 하이퍼파라미터 설정이 필요함**

* K-nearest Neighorhood : 이웃 개체의 수 (k), Neural networks : 은닉 노드의 수 등

**주어진 문제를 해결하기 위한 최적의 방법론을 선택하기 위해 개별 모델을 동등한 조건에서 평가할 필요가 있음**

* 검증 데이터 : 다양한 파라미터 조합 중 최적의 파라미터를 찾는데 주로 사용
* 테스트 데이터 : 여러 기계학습 알고리즘 중 최적의 알고리즘을 찾는데 주로 사용

**시간 정보를 고려할 필요가 없을 경우**

* 원래 데이터를 무작위 추출 방식으로 학습:검증:테스트 데이터셋 으로 분할 (검증 밑 체스트셋의 데이터가 충분히 확보할 수 있는 범위내에서 6:2:2, 8:1:1까지 분할 가능)

* 원칙적으로 무작위로 분할한 데이터셋 구축을 충분히 반복하여 모델의 예측 성능과 안정성을 함께 비교해야함 

  * 무작위 추출은 데이터셋 단위로 수행하며, 한번 추출된 데이터셋으로 비교 대상인 모든 후보 알고리즘에 일괄 적용해야함

  * 알고리즘마다 서로 다르게 무작위 추출된 데이터 셋으로 학습을 수행할 경우 공정한 비교가 불가능함

    
<img width="746" alt="15" src="https://user-images.githubusercontent.com/86525868/191927148-3bf9f57d-42a0-4070-a43f-2f31169a9adb.png">

<img width="770" alt="16" src="https://user-images.githubusercontent.com/86525868/191927151-d9becfd4-8c76-41ae-ba9f-273b73c72ef5.png">

**시간 정보를 반드시 고려해야 하는 경우**

* 반드시 학습:검증:테스트는 시간 순서대로 배열이 되어 있어야 함

  * 무작위 추출 방식을 사용할 경우, 미래 정보를 활용하여 과거를 예측하는 오류를 범하게 됨

* 1번의 검증으로는 앞 선 방식과 같이 모델 성능의 안정성을 평가할 수 없음으로 Sliding Window 방식을 이용한 Time-Series Cross Validation 기법을 활용함 (10개월치의 데이터가 존재하면, 학습:검증:테스트를 2개월:1개월:1개월로 정의, window size=1개월)

<img width="726" alt="17" src="https://user-images.githubusercontent.com/86525868/191927155-7cb65e1b-0c84-45a4-9630-70e4554c98eb.png">

### 예시 : p개의 설비 파라미터로부터 각 제품(GLASS)의 수율을 추정하는 모형

<img width="625" alt="18" src="https://user-images.githubusercontent.com/86525868/191927157-cdc4d4be-7aa7-46fe-9b96-783deab42b8d.png">


#### 지표 1 : 평균오차, Average Error

실제 값에 비해 과대/과소 추정 여부를 판단 (부호로 인해 잘못된 결론을 내릴 위험이 있음)

$$
\text{Average Error}=\frac{1}{n}\sum_{i=1}^n(y_i-y'_i)
$$

<img width="827" alt="20" src="https://user-images.githubusercontent.com/86525868/191927171-b7544d1f-910b-49ce-aabe-4732173d59d8.png">

↳ Average Error는 0.1로 정확한 듯 보이지만 실제값과 예측값의 차이가 양수인 값과 음수인 값들이 상쇄되면서 평균오차가 낮아진 것 


#### 지표 2 : 평균 절대 오차 (Mean Absolute Error, MAE)

실제 값과 예측 값 사이의 절대적인 오차의 평균을 측정 

<img width="813" alt="21" src="https://user-images.githubusercontent.com/86525868/191927173-a729cb5e-cbaf-4183-ab79-559cfbfb34c8.png">

* MAE의 단점 : 실제 값과 예측된 값의 절대 차이에 대한 정보만 제공하고 상대적인 차이에 대한 정보를 제공하지 못함 

  <img width="700" alt="22" src="https://user-images.githubusercontent.com/86525868/191927175-f1d492a2-11b9-461f-bbb0-8a267863469a.png">
  
  두 모델의 MAE는 1로 같지만 절대적인 $Y$라는 정답의 크기 차이가 크기 때문에 왜곡된 결과를 도출

  

#### 지표 3 : 평균 절대 비율 오차 (Mean Absolute Percentage Error, MAPE)

실제값 대비 얼마나 예측 차이가 있는지를 비율(%)로 측정 

상대적인 오차율이 절대적인 오차 수치보다 제조업에서의 품질관리와 같은 분야에서 자주 사용

↳ Target이 넘지 말아야 할 상한선과 하한선 사이에서 얼마만큼의 변동성을 가지고 있는지가 중요한 상황에서 주로 사용

$$
MAPE=\frac{1}{n}\sum_{i=1}^n\Bigg|\frac{y_i-y'_i}{y_i}\Bigg|
$$

<img width="881" alt="23" src="https://user-images.githubusercontent.com/86525868/191927179-dfedd65e-7e1b-4221-8f86-a4b55f24ab76.png">

### MAE와 MAPE를 목적함수로 사용할 경우 추정되는 최귀식의 차이 

<img width="499" alt="24" src="https://user-images.githubusercontent.com/86525868/191927180-512dd4ab-08e6-4f3b-9578-72288be81523.png">

두번째 그래프를 보면 MAPE는 (실제값과 추정값의 차이 / 정답) 을 나타내기 때문에 실제 정답이 0에 가까울 때는 값을 크거나 작게 추정하려고 하지 않음 → 0에 가까운 값에서는 MAPE가 MAE보다 과소 추정하는 것을 볼 수 있음


#### MAE와 MAPE 중 어느 지표를 더 중점적으로 고려해야 하는가?

Domain 마다 다름

* 절대적 차이가 중요한 분야 (추천 시스템의 평점 예측) → MAE
* 상대적 차이가 중요한 분야 (제조업에서의 품질지표 관리) →  MAPE

![25](https://user-images.githubusercontent.com/86525868/191927183-cb94204c-6b31-4cf9-b6ec-f1fec9e9e165.png)

  영화 D에 대한 절대 오차는 1, 상대 오차는 12.5% ($\frac{1}{8}\times 100$)

  하지만, 평점 1점을 2점으로 예측한 상대 오차는 100%, 평점 10점을 9점으로 예측한 오차는 10%로 다름 

  ↳ 상대적인 오차가 아닌 절대적인 오차가 중요함 →  MAE를 주 평가 지표로 사용



#### 지표 4 &5 : (Mean Squared Error, MSE / Root Mean Squared Error, RMSE)

부호의 영향을 제거하기 위해 절대값이 아닌 제곱(제곱합의 제곱근)을 취한 지표

논문에서는 제곱 형태인 MSE, RMSE를 더 선호하지만 현업에서는 직관적으로 볼 수 있는 MAE, MAPE를 더 많이 사용함 

$$
MSE=\frac{1}{n}\sum_{i=1}^n(y_i-y'_i)^2 \quad , \quad RSME=\sqrt{\frac{1}{n}\sum_{i=1}^n(y_i-y'_i)^2}
$$

<img width="771" alt="26" src="https://user-images.githubusercontent.com/86525868/191927185-8f831501-ff5d-486c-99a0-94473e783bc9.png">
