---
title: "[CS231N] 2. Image Classification"
categories:
  - cs231n
  - Image Classification
tags:
  - cs231
  - image classification
toc: true
toc_sticky: true
toc_label: "On This Page"
toc_icon: "bookmark"
use_math: true
---


💡 Iamge Classification <br>
Stanford University "CS231N" 강의를 듣고 정리하였습니다. <br>
{: .notice--info}

자막 : https://github.com/visionNoob/CS231N_17_KOR_SUB (크롬 확장 프로그램 Subtitles for Youtube) <br>
2017 버전 강의 목차 및 슬라이드 : http://cs231n.stanford.edu/2017/syllabus.html <br>
2017 버전 강의 동영상 링크 : https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv <br>
2022 버전 강의 목차 및 슬라이드 : http://cs231n.stanford.edu/schedule.html <br>
실습 과제 : https://github.com/cs231n/cs231n.github.io/tree/master/assignments <br>

# 2. Image Classification

<img width="946" alt="L2_01" src="https://user-images.githubusercontent.com/86525868/170157401-40c15f2e-87e4-489b-ba63-2059dd9c8f91.png">{: width="50%" height="50%"}{: .align-center}

컴퓨터에게 고양이 사진은 큰 격자 모양의 숫자집합으로 인식이 되고 이 거대한 숫자집합에서 **고양이**를 인식하는 것은 어려운 일

사람들은 이 이미지를 **"고양이"**라는 레이블로 인식하고 컴퓨터는 거대한 숫자 집단으로 인식하는 것을 **Semantic Gap(의미론적 차이)**이라고 함

<img width="1240" alt="L2_02" src="https://user-images.githubusercontent.com/86525868/170157543-d507a044-0fd6-4904-8ba4-50f56e4c2709.png">{: .align-center}

하지만 같은 고양이도 각도와 빛, 자세가 달라지면 픽셀들은 모두 달라지고 배경과 비슷한 색의 고양이와 다양한 고양이 종도 모두 고양이라고 인식하는 것은 어려울 수 있음 → **Image Classification 알고리즘은 이런 변수에 강해야 함** <br>



## Data-Driven Approach 

이미지 분류를 가능하게 하는 하나의 Insight로 Data-Driven Approach(데이터 중심 접근 방법)이 있음

고양이는 무엇이다, 물고기는 무엇이다라고 직접 규칙을 써내려가는 것 대신에 Google Image Serach와 같은 도구로 많은 데이터를 수집하고 이 데이터 셋을 이용해 Machine Learning Classifier를 학습시킬 수 있음

ML Algorithm은 데이터를 요약해서 다양한 객체들을 인식할 수 있는 모델을 만들고 학습 모델로 새로운 이미지를 테스트하면 사물을 인식할 수 있음 → Machine Learning의 Key Insight인 **두 개의 함수 필요**

1. Train Function → input = image, label / output = model 
2. Predict Function → input = model / output = predict <br>




## First Classifier : Nearest Neighbor

1. Memorize all data and labels

   ```python
   def train(images, labels):
   	# Machine Learning
     return model
   ```

2. Predict the label of the most similar training image

   ```python
   def predict(model, test_images):
   	# Use model to predict labels
   	return test_labels
   ```

간단한 모델이지만 Data-Driven Approach를 이해하기 좋은 Algorithm <br>



### CIFAR-10

총 50,000여개의 학습용 이미지가 각 10개의 카테고리에 균일하게 분포되어 있고 10,000여개의 테스트 이미지로 이루어진 데이터 셋 

<img width="998" alt="L2_03" src="https://user-images.githubusercontent.com/86525868/170157675-16886d7a-143c-4b43-a1d1-29d0c3a4e5cb.png">{: width="80%" height="80%"}{: .align-center}


오른쪽 칸의 맨 왼쪽 열은 CIFAR-10의 테스트 이미지이고 오른쪽 방향으로 학습 이미지 중 테스트 이미지와 유사한 순으로 정렬 되어 있음

NN Algorithm을 적용시키면 트레이닝 셋에서 **가장 가까운 샘플**을 찾게되고 **가장 가까운 샘플**의 레이블로 테스트 이미지의 레이블을 알 수 있음

❗️중요한 점은 test image와 train image를 어떻게 비교하는가 = **어떤 비교 함수를 사용할 것인가**❗️ <br>



### Distance Metric to compare images : L1 distance 

$$
d_1(I_1, I_2)=\sum_p |I_1^p-I_2^p|
$$

<img width="1134" alt="L2_04" src="https://user-images.githubusercontent.com/86525868/170157685-537d9704-a0e3-4c83-8b2b-57143683dc09.png">{: width="50%" height="50%"}{: .align-center}


L1 distance는 이미지를 Pixel-Wise로 비교 → **두 이미지간의 차이를 어떻게 측정할 것인가에 구체적인 방법을 제시**

```python
import numpy as np

class NearestNeighbor(object):
  def __init__(self):
    pass

  def train(self, X, y):
    """ X is N x D where each row is an example. Y is 1-dimension of size N """
    # the nearest neighbor classifier simply remembers all the training data
    self.Xtr = X
    self.ytr = y

  def predict(self, X):
    """ X is N x D where each row is an example we wish to predict label for """
    num_test = X.shape[0]
    # lets make sure that the output type matches the input type
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)

    # loop over all test rows
    for i in range(num_test):
      # find the nearest training image to the i'th test image
      # using the L1 distance (sum of absolute value differences)
      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
      min_index = np.argmin(distances) # get the index with smallest distance
      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example

    return Ypred
```

Train Function에서는 학습 데이터를 기억하고 Test Function에서는 이미지를 입력으로 받고 L1 Distance로 비교하며 학습 데이터 중에서 테스트 이미지와 가장 유사한 이미지를 찾아냄 

**Q1. With NN examples, how fast are training and prediction?**

* Train time은 데이터를 기억하기 때문에 상수시간이 걸리지만 Test time은 N개의 학습 데이터를 전부 테스트 이미지와 비교하기 때문에 상당한 시간이 소요됨 → **우리는 반대의 상황을 기대 (Classifier의 좋은 성능을 위해 train time에 투자 하는 방향으로 기대)** <br>


### K-NN Algorithm

**NN's Decision Regions**

각 점은 학습데이터이고 점의 색은 카테고리를 뜻하고 모든 좌표에서 각 좌표가 어떤 학습 데이터와 가장 가까운지 계산하고 각 좌표를 해당 카테고리로 칠함

NN Classifier은 공간을 나눠서 각 카테고리로 분류함

<img width="1159" alt="L2_05" src="https://user-images.githubusercontent.com/86525868/170157708-67bb7a7d-28b5-4699-87ee-5c6b0aa4486e.png">{: width="80%" height="80%"}{: .align-center}


* **K = 1** : NN Algorithm, 가장 가까운 이웃만을 보기 때문에 녹색 영역 중간에 노란색 영역이 생기고 파란색 영역에 녹색이 침범 (NN Classifier에서 발생 가능한 문제점) → **noise와 spurious**

이런 문제를 해결하기 위해 일반화된 버전인 **K-NN Algorithm**이 탄생 → **Distance metric을 이용하여 가까운 이웃을 K개 만큼 찾고, 이웃끼리 투표하는 방법**

* **K = 3** : 녹색 영역이 깔끔해지고 빨강, 파랑 영역의 경계들도 부드러워짐 
* **K = 5** : 각 영역들의 경계가 더 부드러워짐 <br>



**K-Nearest Neighbors : Distance Metric**

![L2_06](https://user-images.githubusercontent.com/86525868/170157732-2193baa2-a8f1-4d6f-a252-caecf34999bc.jpeg){: .align-center}


지금까지 L1 Distance 만 고려했지만 L2 Distance도 사용할 수 있음 → **공간의 근본적인 기하학적 구조가 다름**

좌표계를 회전시킨다면 L1 Distance는 변하지만 L2 Distance는 변하지 않음 → **L1은 좌표축의 영향을 받지만, L2는 고르게 영향을 받음**

* **L1 Distance**
  * 특징 벡터의 각각 요소들이 개별적인 의미를 가지고 있는 경우 → **특정 벡터의 영향이 강하게 적용됨**
  * 좌표 시스템의 영향을 받고 결정 경계를 만듦 → 부자연스러움
* **L2 Distance** 
  * 특징 벡터가 일반적인 벡터이고 요소들간 실질적인 의미를 잘 모르는 경우 → **특정 벡터의 영향이 고르게 적용됨**
  * 좌표 시스템의 영향을 받지 않고 결정 경계를 만듦 → 자연스러움




