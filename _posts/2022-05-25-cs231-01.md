---
title: "[CS231N] 2. Image Classification"
categories:
  - cs231n
  - Image Classification
tags:
  - cs231
  - image classification
toc: true
toc_sticky: true
toc_label: "On This Page"
toc_icon: "bookmark"
use_math: true
---


ğŸ’¡ Iamge Classification <br>
Stanford University "CS231N" ê°•ì˜ë¥¼ ë“£ê³  ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤. <br>
{: .notice--info}

ìë§‰ : https://github.com/visionNoob/CS231N_17_KOR_SUB (í¬ë¡¬ í™•ì¥ í”„ë¡œê·¸ë¨ Subtitles for Youtube) <br>
2017 ë²„ì „ ê°•ì˜ ëª©ì°¨ ë° ìŠ¬ë¼ì´ë“œ : http://cs231n.stanford.edu/2017/syllabus.html <br>
2017 ë²„ì „ ê°•ì˜ ë™ì˜ìƒ ë§í¬ : https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv <br>
2022 ë²„ì „ ê°•ì˜ ëª©ì°¨ ë° ìŠ¬ë¼ì´ë“œ : http://cs231n.stanford.edu/schedule.html <br>
ì‹¤ìŠµ ê³¼ì œ : https://github.com/cs231n/cs231n.github.io/tree/master/assignments <br>

# 2. Image Classification

<img width="946" alt="L2_01" src="https://user-images.githubusercontent.com/86525868/170157401-40c15f2e-87e4-489b-ba63-2059dd9c8f91.png">{: width="50%" height="50%"}{: .align-center}

ì»´í“¨í„°ì—ê²Œ ê³ ì–‘ì´ ì‚¬ì§„ì€ í° ê²©ì ëª¨ì–‘ì˜ ìˆ«ìì§‘í•©ìœ¼ë¡œ ì¸ì‹ì´ ë˜ê³  ì´ ê±°ëŒ€í•œ ìˆ«ìì§‘í•©ì—ì„œ **ê³ ì–‘ì´**ë¥¼ ì¸ì‹í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ì¼

ì‚¬ëŒë“¤ì€ ì´ ì´ë¯¸ì§€ë¥¼ **"ê³ ì–‘ì´"**ë¼ëŠ” ë ˆì´ë¸”ë¡œ ì¸ì‹í•˜ê³  ì»´í“¨í„°ëŠ” ê±°ëŒ€í•œ ìˆ«ì ì§‘ë‹¨ìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ê²ƒì„ **Semantic Gap(ì˜ë¯¸ë¡ ì  ì°¨ì´)**ì´ë¼ê³  í•¨

<img width="1240" alt="L2_02" src="https://user-images.githubusercontent.com/86525868/170157543-d507a044-0fd6-4904-8ba4-50f56e4c2709.png">{: .align-center}

í•˜ì§€ë§Œ ê°™ì€ ê³ ì–‘ì´ë„ ê°ë„ì™€ ë¹›, ìì„¸ê°€ ë‹¬ë¼ì§€ë©´ í”½ì…€ë“¤ì€ ëª¨ë‘ ë‹¬ë¼ì§€ê³  ë°°ê²½ê³¼ ë¹„ìŠ·í•œ ìƒ‰ì˜ ê³ ì–‘ì´ì™€ ë‹¤ì–‘í•œ ê³ ì–‘ì´ ì¢…ë„ ëª¨ë‘ ê³ ì–‘ì´ë¼ê³  ì¸ì‹í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ â†’ **Image Classification ì•Œê³ ë¦¬ì¦˜ì€ ì´ëŸ° ë³€ìˆ˜ì— ê°•í•´ì•¼ í•¨** <br>



## Data-Driven Approach 

ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•˜ë‚˜ì˜ Insightë¡œ Data-Driven Approach(ë°ì´í„° ì¤‘ì‹¬ ì ‘ê·¼ ë°©ë²•)ì´ ìˆìŒ

ê³ ì–‘ì´ëŠ” ë¬´ì—‡ì´ë‹¤, ë¬¼ê³ ê¸°ëŠ” ë¬´ì—‡ì´ë‹¤ë¼ê³  ì§ì ‘ ê·œì¹™ì„ ì¨ë‚´ë ¤ê°€ëŠ” ê²ƒ ëŒ€ì‹ ì— Google Image Serachì™€ ê°™ì€ ë„êµ¬ë¡œ ë§ì€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì´ ë°ì´í„° ì…‹ì„ ì´ìš©í•´ Machine Learning Classifierë¥¼ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŒ

ML Algorithmì€ ë°ì´í„°ë¥¼ ìš”ì•½í•´ì„œ ë‹¤ì–‘í•œ ê°ì²´ë“¤ì„ ì¸ì‹í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³  í•™ìŠµ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ í…ŒìŠ¤íŠ¸í•˜ë©´ ì‚¬ë¬¼ì„ ì¸ì‹í•  ìˆ˜ ìˆìŒ â†’ Machine Learningì˜ Key Insightì¸ **ë‘ ê°œì˜ í•¨ìˆ˜ í•„ìš”**

1. Train Function â†’ input = image, label / output = model 
2. Predict Function â†’ input = model / output = predict <br>




## First Classifier : Nearest Neighbor

1. Memorize all data and labels

   ```python
   def train(images, labels):
   	# Machine Learning
     return model
   ```

2. Predict the label of the most similar training image

   ```python
   def predict(model, test_images):
   	# Use model to predict labels
   	return test_labels
   ```

ê°„ë‹¨í•œ ëª¨ë¸ì´ì§€ë§Œ Data-Driven Approachë¥¼ ì´í•´í•˜ê¸° ì¢‹ì€ Algorithm <br>



### CIFAR-10

ì´ 50,000ì—¬ê°œì˜ í•™ìŠµìš© ì´ë¯¸ì§€ê°€ ê° 10ê°œì˜ ì¹´í…Œê³ ë¦¬ì— ê· ì¼í•˜ê²Œ ë¶„í¬ë˜ì–´ ìˆê³  10,000ì—¬ê°œì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ì´ë£¨ì–´ì§„ ë°ì´í„° ì…‹ 

<img width="998" alt="L2_03" src="https://user-images.githubusercontent.com/86525868/170157675-16886d7a-143c-4b43-a1d1-29d0c3a4e5cb.png">{: width="80%" height="80%"}{: .align-center}


ì˜¤ë¥¸ìª½ ì¹¸ì˜ ë§¨ ì™¼ìª½ ì—´ì€ CIFAR-10ì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì´ê³  ì˜¤ë¥¸ìª½ ë°©í–¥ìœ¼ë¡œ í•™ìŠµ ì´ë¯¸ì§€ ì¤‘ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ìˆœìœ¼ë¡œ ì •ë ¬ ë˜ì–´ ìˆìŒ

NN Algorithmì„ ì ìš©ì‹œí‚¤ë©´ íŠ¸ë ˆì´ë‹ ì…‹ì—ì„œ **ê°€ì¥ ê°€ê¹Œìš´ ìƒ˜í”Œ**ì„ ì°¾ê²Œë˜ê³  **ê°€ì¥ ê°€ê¹Œìš´ ìƒ˜í”Œ**ì˜ ë ˆì´ë¸”ë¡œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ë ˆì´ë¸”ì„ ì•Œ ìˆ˜ ìˆìŒ

â—ï¸ì¤‘ìš”í•œ ì ì€ test imageì™€ train imageë¥¼ ì–´ë–»ê²Œ ë¹„êµí•˜ëŠ”ê°€ = **ì–´ë–¤ ë¹„êµ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ê²ƒì¸ê°€**â—ï¸ <br>



### Distance Metric to compare images : L1 distance 

$$
d_1(I_1, I_2)=\sum_p |I_1^p-I_2^p|
$$

<img width="1134" alt="L2_04" src="https://user-images.githubusercontent.com/86525868/170157685-537d9704-a0e3-4c83-8b2b-57143683dc09.png">{: width="50%" height="50%"}{: .align-center}


L1 distanceëŠ” ì´ë¯¸ì§€ë¥¼ Pixel-Wiseë¡œ ë¹„êµ â†’ **ë‘ ì´ë¯¸ì§€ê°„ì˜ ì°¨ì´ë¥¼ ì–´ë–»ê²Œ ì¸¡ì •í•  ê²ƒì¸ê°€ì— êµ¬ì²´ì ì¸ ë°©ë²•ì„ ì œì‹œ**

```python
import numpy as np

class NearestNeighbor(object):
  def __init__(self):
    pass

  def train(self, X, y):
    """ X is N x D where each row is an example. Y is 1-dimension of size N """
    # the nearest neighbor classifier simply remembers all the training data
    self.Xtr = X
    self.ytr = y

  def predict(self, X):
    """ X is N x D where each row is an example we wish to predict label for """
    num_test = X.shape[0]
    # lets make sure that the output type matches the input type
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)

    # loop over all test rows
    for i in range(num_test):
      # find the nearest training image to the i'th test image
      # using the L1 distance (sum of absolute value differences)
      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
      min_index = np.argmin(distances) # get the index with smallest distance
      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example

    return Ypred
```

Train Functionì—ì„œëŠ” í•™ìŠµ ë°ì´í„°ë¥¼ ê¸°ì–µí•˜ê³  Test Functionì—ì„œëŠ” ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³  L1 Distanceë¡œ ë¹„êµí•˜ë©° í•™ìŠµ ë°ì´í„° ì¤‘ì—ì„œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì•„ëƒ„ 

**Q1. With NN examples, how fast are training and prediction?**

* Train timeì€ ë°ì´í„°ë¥¼ ê¸°ì–µí•˜ê¸° ë•Œë¬¸ì— ìƒìˆ˜ì‹œê°„ì´ ê±¸ë¦¬ì§€ë§Œ Test timeì€ Nê°œì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ì „ë¶€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ë¹„êµí•˜ê¸° ë•Œë¬¸ì— ìƒë‹¹í•œ ì‹œê°„ì´ ì†Œìš”ë¨ â†’ **ìš°ë¦¬ëŠ” ë°˜ëŒ€ì˜ ìƒí™©ì„ ê¸°ëŒ€ (Classifierì˜ ì¢‹ì€ ì„±ëŠ¥ì„ ìœ„í•´ train timeì— íˆ¬ì í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ê¸°ëŒ€)** <br>


### K-NN Algorithm

**NN's Decision Regions**

ê° ì ì€ í•™ìŠµë°ì´í„°ì´ê³  ì ì˜ ìƒ‰ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ëœ»í•˜ê³  ëª¨ë“  ì¢Œí‘œì—ì„œ ê° ì¢Œí‘œê°€ ì–´ë–¤ í•™ìŠµ ë°ì´í„°ì™€ ê°€ì¥ ê°€ê¹Œìš´ì§€ ê³„ì‚°í•˜ê³  ê° ì¢Œí‘œë¥¼ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¡œ ì¹ í•¨

NN Classifierì€ ê³µê°„ì„ ë‚˜ëˆ ì„œ ê° ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•¨

<img width="1159" alt="L2_05" src="https://user-images.githubusercontent.com/86525868/170157708-67bb7a7d-28b5-4699-87ee-5c6b0aa4486e.png">{: width="80%" height="80%"}{: .align-center}


* **K = 1** : NN Algorithm, ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒë§Œì„ ë³´ê¸° ë•Œë¬¸ì— ë…¹ìƒ‰ ì˜ì—­ ì¤‘ê°„ì— ë…¸ë€ìƒ‰ ì˜ì—­ì´ ìƒê¸°ê³  íŒŒë€ìƒ‰ ì˜ì—­ì— ë…¹ìƒ‰ì´ ì¹¨ë²” (NN Classifierì—ì„œ ë°œìƒ ê°€ëŠ¥í•œ ë¬¸ì œì ) â†’ **noiseì™€ spurious**

ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì¼ë°˜í™”ëœ ë²„ì „ì¸ **K-NN Algorithm**ì´ íƒ„ìƒ â†’ **Distance metricì„ ì´ìš©í•˜ì—¬ ê°€ê¹Œìš´ ì´ì›ƒì„ Kê°œ ë§Œí¼ ì°¾ê³ , ì´ì›ƒë¼ë¦¬ íˆ¬í‘œí•˜ëŠ” ë°©ë²•**

* **K = 3** : ë…¹ìƒ‰ ì˜ì—­ì´ ê¹”ë”í•´ì§€ê³  ë¹¨ê°•, íŒŒë‘ ì˜ì—­ì˜ ê²½ê³„ë“¤ë„ ë¶€ë“œëŸ¬ì›Œì§ 
* **K = 5** : ê° ì˜ì—­ë“¤ì˜ ê²½ê³„ê°€ ë” ë¶€ë“œëŸ¬ì›Œì§ <br>



**K-Nearest Neighbors : Distance Metric**

![L2_06](https://user-images.githubusercontent.com/86525868/170157732-2193baa2-a8f1-4d6f-a252-caecf34999bc.jpeg){: .align-center}


ì§€ê¸ˆê¹Œì§€ L1 Distance ë§Œ ê³ ë ¤í–ˆì§€ë§Œ L2 Distanceë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ â†’ **ê³µê°„ì˜ ê·¼ë³¸ì ì¸ ê¸°í•˜í•™ì  êµ¬ì¡°ê°€ ë‹¤ë¦„**

ì¢Œí‘œê³„ë¥¼ íšŒì „ì‹œí‚¨ë‹¤ë©´ L1 DistanceëŠ” ë³€í•˜ì§€ë§Œ L2 DistanceëŠ” ë³€í•˜ì§€ ì•ŠìŒ â†’ **L1ì€ ì¢Œí‘œì¶•ì˜ ì˜í–¥ì„ ë°›ì§€ë§Œ, L2ëŠ” ê³ ë¥´ê²Œ ì˜í–¥ì„ ë°›ìŒ**

* **L1 Distance**
  * íŠ¹ì§• ë²¡í„°ì˜ ê°ê° ìš”ì†Œë“¤ì´ ê°œë³„ì ì¸ ì˜ë¯¸ë¥¼ ê°€ì§€ê³  ìˆëŠ” ê²½ìš° â†’ **íŠ¹ì • ë²¡í„°ì˜ ì˜í–¥ì´ ê°•í•˜ê²Œ ì ìš©ë¨**
  * ì¢Œí‘œ ì‹œìŠ¤í…œì˜ ì˜í–¥ì„ ë°›ê³  ê²°ì • ê²½ê³„ë¥¼ ë§Œë“¦ â†’ ë¶€ìì—°ìŠ¤ëŸ¬ì›€
* **L2 Distance** 
  * íŠ¹ì§• ë²¡í„°ê°€ ì¼ë°˜ì ì¸ ë²¡í„°ì´ê³  ìš”ì†Œë“¤ê°„ ì‹¤ì§ˆì ì¸ ì˜ë¯¸ë¥¼ ì˜ ëª¨ë¥´ëŠ” ê²½ìš° â†’ **íŠ¹ì • ë²¡í„°ì˜ ì˜í–¥ì´ ê³ ë¥´ê²Œ ì ìš©ë¨**
  * ì¢Œí‘œ ì‹œìŠ¤í…œì˜ ì˜í–¥ì„ ë°›ì§€ ì•Šê³  ê²°ì • ê²½ê³„ë¥¼ ë§Œë“¦ â†’ ìì—°ìŠ¤ëŸ¬ì›€




